{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-------------------------- set gpu using tf ---------------------------\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "session = tf.Session(config=config)\n",
    "#-------------------  start importing keras module ---------------------\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from scipy.misc import imresize\n",
    "import tensorflow as tf\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.callbacks as callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./all/fer2013/fer2013.csv', dtype={'emotion':np.int32, 'pixels':str, 'Usage':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pixels'] = df['pixels'].apply(lambda x: np.fromstring(x,sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc[df['Usage'] == 'Training']\n",
    "validation = df.loc[df['Usage'] == 'PublicTest']\n",
    "test = df.loc[df['Usage'] == 'PrivateTest']\n",
    "\n",
    "y_train = pd.get_dummies(train['emotion'])\n",
    "y_train.columns = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']\n",
    "\n",
    "y_val = pd.get_dummies(validation['emotion'])\n",
    "y_val.columns = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']\n",
    "\n",
    "y_test = pd.get_dummies(test['emotion'])\n",
    "y_test.columns = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack(train['pixels'].values)\n",
    "x_validation = np.vstack(validation['pixels'].values)\n",
    "x_test = np.vstack(test['pixels'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = np.stack((np.reshape(x_train,(-1, 48, 48, 1)),)*3, axis=-2).squeeze()\n",
    "X_val = np.stack((np.reshape(x_validation,(-1, 48, 48, 1)),)*3, axis=-2).squeeze()\n",
    "X_test =  np.stack((np.reshape(x_test,(-1, 48, 48, 1)),)*3, axis=-2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(color_files, y, folder):\n",
    "    numbers = []\n",
    "    for item in color_files:\n",
    "        for subitem in item.split('_'):\n",
    "            if(subitem.isdigit()):\n",
    "                numbers.append(subitem)\n",
    "\n",
    "    X_color = np.empty((len(numbers), 48, 48, 3)).astype('uint8')\n",
    "    y_color = np.empty((len(numbers), 7))\n",
    "\n",
    "    for i in range(len(numbers)):\n",
    "\n",
    "        path = folder + color_files[i]\n",
    "        val = int(numbers[i])\n",
    "\n",
    "        X_color[i] = np.array(imread(path)).astype('uint8')\n",
    "        y_color[i] = y.iloc[val]\n",
    "        \n",
    "    return X_color, y_color, numbers\n",
    "\n",
    "    #np.save('train_data', colorVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_color_files = [k for k in os.listdir('train_color/') if '_color' in k]\n",
    "\n",
    "X_train, y_train, indices_train = get_color(train_color_files, y_train, './train_color/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_testval, y_train, y_testval = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_testval, y_testval, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.device('/cpu:0'):\n",
    "#    tf_x_train = tf.placeholder(tf.float32, shape=(len(X_train), 48, 48, 3))\n",
    "#    tf_x_validation = tf.placeholder(tf.float32, shape=(len(X_val), 48, 48, 3))\n",
    "#    tf_x_test = tf.placeholder(tf.float32, shape=(len(X_test), 48, 48, 3))\n",
    "\n",
    "#    tf_x_train_resized = tf.image.resize_images(tf_x_train,  size=[75,75])\n",
    "#    tf_x_validation_resized = tf.image.resize_images(tf_x_validation,  size=[75,75])\n",
    "#    tf_x_test_resized = tf.image.resize_images(tf_x_test,  size=[75,75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "#    X_train,X_val,X_test = sess.run([tf_x_train_resized,tf_x_validation_resized,tf_x_test_resized], feed_dict={tf_x_train: X_train,\n",
    "#                                                   tf_x_validation: X_val,\n",
    "#                                                   tf_x_test: X_test\n",
    "#                                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zca_whitening=True,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_imagenet = applications.densenet.DenseNet201(include_top=False, weights='imagenet', input_shape=(48, 48, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_imagenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_imagenet.layers[-1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add new classification layers\n",
    "x = model_imagenet.layers[-1].output\n",
    "x = Flatten()(x)\n",
    "x = Dense(7)(x)\n",
    "x = Activation('softmax', name='new_loss')(x)\n",
    "\n",
    "#new Model\n",
    "model = Model(model_imagenet.inputs, x, name='model_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for layer in model.layers:\n",
    "#    layer.trainable = True\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_imagenet.output.shape)\n",
    "print(model.output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_val = 2**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = callbacks.TensorBoard(log_dir = \"./tensorboard/\")\n",
    "early_stopping_callback = callbacks.EarlyStopping(monitor='val_acc', patience=5, mode='max')\n",
    "checkpoint_callback = callbacks.ModelCheckpoint('densenet201_fine_tunning.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compile model and train it.\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr = 0.0001), metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size_val),\n",
    "                              validation_data=datagen.flow(X_val, y_val, batch_size=batch_size_val), \n",
    "                              steps_per_epoch=len(X_train) / batch_size_val, epochs=100, callbacks=[early_stopping_callback, checkpoint_callback, tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate on validation:\n",
    "# ...\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate_generator(datagen.flow(X_val, y_val, batch_size=batch_size_val), steps=len(X_val)/batch_size_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test:\n",
    "# ...\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate_generator(datagen.flow(X_test, y_test, batch_size=batch_size_val), steps=len(X_test)/batch_size_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
