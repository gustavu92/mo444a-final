{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-------------------------- set gpu using tf ---------------------------\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "session = tf.Session(config=config)\n",
    "#-------------------  start importing keras module ---------------------\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import TensorBoard\n",
    "# from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from scipy.misc import imresize\n",
    "import tensorflow as tf\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.callbacks as callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../fer2013/fer2013.csv', dtype={'emotion':np.int32, 'pixels':str, 'Usage':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pixels'] = df['pixels'].apply(lambda x: np.fromstring(x,sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc[df['Usage'] == 'Training']\n",
    "validation = df.loc[df['Usage'] == 'PublicTest']\n",
    "test = df.loc[df['Usage'] == 'PrivateTest']\n",
    "\n",
    "y_train = pd.get_dummies(train['emotion'])\n",
    "y_train.columns = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']\n",
    "\n",
    "y_val = pd.get_dummies(validation['emotion'])\n",
    "y_val.columns = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']\n",
    "\n",
    "y_test = pd.get_dummies(test['emotion'])\n",
    "y_test.columns = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack(train['pixels'].values)\n",
    "x_validation = np.vstack(validation['pixels'].values)\n",
    "x_test = np.vstack(test['pixels'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.stack((np.reshape(x_train,(-1, 48, 48, 1)),)*3, axis=-2).squeeze()\n",
    "X_val = np.stack((np.reshape(x_validation,(-1, 48, 48, 1)),)*3, axis=-2).squeeze()\n",
    "X_test =  np.stack((np.reshape(x_test,(-1, 48, 48, 1)),)*3, axis=-2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(color_files, y, folder):\n",
    "    numbers = []\n",
    "    for item in color_files:\n",
    "        for subitem in item.split('_'):\n",
    "            if(subitem.isdigit()):\n",
    "                numbers.append(subitem)\n",
    "\n",
    "    X_color = np.empty((len(numbers), 48, 48, 3)).astype('uint8')\n",
    "    y_color = np.empty((len(numbers), 7))\n",
    "\n",
    "    for i in range(len(numbers)):\n",
    "\n",
    "        path = folder + color_files[i]\n",
    "        val = int(numbers[i])\n",
    "\n",
    "        X_color[i] = np.array(imread(path)).astype('uint8')\n",
    "        y_color[i] = y.iloc[val]\n",
    "        \n",
    "    return X_color, y_color, numbers\n",
    "\n",
    "    #np.save('train_data', colorVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_color_files = [k for k in os.listdir('train_color/') if '_color' in k]\n",
    "\n",
    "# X_train, y_train, indices_train = get_color(train_color_files, y_train, './train_color/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_testval, y_train, y_testval = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val, X_test, y_val, y_test = train_test_split(X_testval, y_testval, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    tf_x_train = tf.placeholder(tf.float32, shape=(len(X_train), 48, 48, 3))\n",
    "    tf_x_validation = tf.placeholder(tf.float32, shape=(len(X_val), 48, 48, 3))\n",
    "    tf_x_test = tf.placeholder(tf.float32, shape=(len(X_test), 48, 48, 3))\n",
    "\n",
    "    tf_x_train_resized = tf.image.resize_images(tf_x_train,  size=[75,75])\n",
    "    tf_x_validation_resized = tf.image.resize_images(tf_x_validation,  size=[75,75])\n",
    "    tf_x_test_resized = tf.image.resize_images(tf_x_test,  size=[75,75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    X_train,X_val,X_test = sess.run([tf_x_train_resized,tf_x_validation_resized,tf_x_test_resized], feed_dict={tf_x_train: X_train,\n",
    "                                                   tf_x_validation: X_val,\n",
    "                                                   tf_x_test: X_test\n",
    "                                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 75, 75, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datagen = ImageDataGenerator(\n",
    "#    samplewise_center=True,\n",
    "#    samplewise_std_normalization=True,\n",
    "#    horizontal_flip=True,\n",
    "#    vertical_flip=False)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_imagenet = applications.vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(75, 75, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 75, 75, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 75, 75, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 37, 37, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 9, 9, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_imagenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'block5_pool'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imagenet.layers[-1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add new classification layers\n",
    "x = model_imagenet.layers[-1].output\n",
    "x = Flatten()(x)\n",
    "x = Dense(7)(x)\n",
    "x = Activation('softmax', name='new_loss')(x)\n",
    "\n",
    "#new Model\n",
    "model = Model(model_imagenet.inputs, x, name='model_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 75, 75, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 75, 75, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 37, 37, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 9, 9, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 14343     \n",
      "_________________________________________________________________\n",
      "new_loss (Activation)        (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 14,729,031\n",
      "Trainable params: 14,729,031\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "block1_conv1 True\n",
      "block1_conv2 True\n",
      "block1_pool True\n",
      "block2_conv1 True\n",
      "block2_conv2 True\n",
      "block2_pool True\n",
      "block3_conv1 True\n",
      "block3_conv2 True\n",
      "block3_conv3 True\n",
      "block3_pool True\n",
      "block4_conv1 True\n",
      "block4_conv2 True\n",
      "block4_conv3 True\n",
      "block4_pool True\n",
      "block5_conv1 True\n",
      "block5_conv2 True\n",
      "block5_conv3 True\n",
      "block5_pool True\n",
      "flatten_1 True\n",
      "dense_1 True\n",
      "new_loss True\n"
     ]
    }
   ],
   "source": [
    "#for layer in model.layers:\n",
    "#    layer.trainable = True\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2, 2, 512)\n",
      "(?, 7)\n"
     ]
    }
   ],
   "source": [
    "print(model_imagenet.output.shape)\n",
    "print(model.output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_val = 2**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = callbacks.TensorBoard(log_dir = \"./tensorboard/\")\n",
    "early_stopping_callback = callbacks.EarlyStopping(monitor='val_acc', patience=5, mode='max')\n",
    "checkpoint_callback = callbacks.ModelCheckpoint('vgg16_fine_tuning.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "225/224 [==============================] - 120s 534ms/step - loss: 1.3618 - acc: 0.4754 - val_loss: 1.1671 - val_acc: 0.5439\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.54388, saving model to vgg16_fine_tuning.h5\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 112s 498ms/step - loss: 1.0597 - acc: 0.5971 - val_loss: 1.0664 - val_acc: 0.5943\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.54388 to 0.59432, saving model to vgg16_fine_tuning.h5\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 112s 498ms/step - loss: 0.9303 - acc: 0.6502 - val_loss: 0.9874 - val_acc: 0.6347\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.59432 to 0.63472, saving model to vgg16_fine_tuning.h5\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 111s 495ms/step - loss: 0.8133 - acc: 0.6982 - val_loss: 0.9720 - val_acc: 0.6422\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.63472 to 0.64224, saving model to vgg16_fine_tuning.h5\n",
      "Epoch 5/100\n",
      "225/224 [==============================] - 112s 496ms/step - loss: 0.6969 - acc: 0.7426 - val_loss: 1.0130 - val_acc: 0.6403\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.64224\n",
      "Epoch 6/100\n",
      "225/224 [==============================] - 112s 499ms/step - loss: 0.5632 - acc: 0.7959 - val_loss: 1.0032 - val_acc: 0.6590\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.64224 to 0.65896, saving model to vgg16_fine_tuning.h5\n",
      "Epoch 7/100\n",
      "225/224 [==============================] - 112s 499ms/step - loss: 0.4228 - acc: 0.8479 - val_loss: 1.1542 - val_acc: 0.6643\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.65896 to 0.66425, saving model to vgg16_fine_tuning.h5\n",
      "Epoch 8/100\n",
      "225/224 [==============================] - 112s 498ms/step - loss: 0.3029 - acc: 0.8918 - val_loss: 1.2554 - val_acc: 0.6595\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.66425\n",
      "Epoch 9/100\n",
      "225/224 [==============================] - 112s 498ms/step - loss: 0.2112 - acc: 0.9264 - val_loss: 1.4208 - val_acc: 0.6590\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.66425\n",
      "Epoch 10/100\n",
      "225/224 [==============================] - 113s 501ms/step - loss: 0.1559 - acc: 0.9463 - val_loss: 1.5006 - val_acc: 0.6576\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.66425\n",
      "Epoch 11/100\n",
      "225/224 [==============================] - 112s 497ms/step - loss: 0.1158 - acc: 0.9608 - val_loss: 1.5615 - val_acc: 0.6732\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.66425 to 0.67317, saving model to vgg16_fine_tuning.h5\n",
      "Epoch 12/100\n",
      "225/224 [==============================] - 112s 499ms/step - loss: 0.0992 - acc: 0.9679 - val_loss: 1.5988 - val_acc: 0.6542\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.67317\n",
      "Epoch 13/100\n",
      "225/224 [==============================] - 112s 496ms/step - loss: 0.0805 - acc: 0.9736 - val_loss: 1.7875 - val_acc: 0.6612\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.67317\n",
      "Epoch 14/100\n",
      "225/224 [==============================] - 112s 499ms/step - loss: 0.0707 - acc: 0.9766 - val_loss: 1.8379 - val_acc: 0.6687\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.67317\n",
      "Epoch 15/100\n",
      "225/224 [==============================] - 112s 497ms/step - loss: 0.0730 - acc: 0.9755 - val_loss: 1.7796 - val_acc: 0.6690\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.67317\n",
      "Epoch 16/100\n",
      "225/224 [==============================] - 112s 497ms/step - loss: 0.0575 - acc: 0.9814 - val_loss: 2.0594 - val_acc: 0.6679\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.67317\n"
     ]
    }
   ],
   "source": [
    "# Compile model and train it.\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr = 0.0001), metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size_val),\n",
    "                              validation_data=datagen.flow(X_val, y_val, batch_size=batch_size_val), \n",
    "                              steps_per_epoch=len(X_train) / batch_size_val, epochs=100, \n",
    "                              validation_steps=len(X_val)/batch_size_val,\n",
    "                              callbacks=[early_stopping_callback, checkpoint_callback, tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[2.0594294728193816, 0.6678740596598521]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation:\n",
    "# ...\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate_generator(datagen.flow(X_val, y_val, batch_size=batch_size_val), steps=len(X_val)/batch_size_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.9681121640698296, 0.6792978545638904]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test:\n",
    "# ...\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate_generator(datagen.flow(X_test, y_test, batch_size=batch_size_val), steps=len(X_test)/batch_size_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
