{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras_svm import sequential_with_svm\n",
    "\n",
    "# Keras imports\n",
    "\n",
    "from keras.layers import Input, Conv2D, Convolution2D, MaxPooling2D, Activation, Average, concatenate, Dropout, GlobalAveragePooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers, optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "try:\n",
    "    from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "except:\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire Module Definition\n",
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    channel_axis = 3\n",
    "    \n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "#SqueezeNet model definition\n",
    "def SqueezeNet(model_input):\n",
    "#     img_input = Input(shape=input_shape) #placeholder\n",
    "    img_input = model_input\n",
    "    \n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='squeeze_conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "    x = Convolution2D(1000, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='loss')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "\n",
    "    # Download and load ImageNet weights\n",
    "    model.load_weights('./squeezenet_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "    \n",
    "    return model    \n",
    "\n",
    "def newSqueezeNet(model_input):\n",
    "    #Add new classification layers\n",
    "    x = model_input.layers[-5].output\n",
    "    x = Convolution2D(7, (1, 1), padding='valid', name='new_conv10')(x)\n",
    "    x = Activation('relu', name='new_relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='new_loss')(x)\n",
    "    model = Model(squeezeModel.inputs, x, name='squeezenet')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_pool_cnn(model_input):\n",
    "    \n",
    "    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding =    'same')(model_input)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(7, (1, 1))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='conv_pool_cnn')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_cnn(model_input):\n",
    "    \n",
    "    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding = 'same')(model_input)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same', strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same', strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(192, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(7, (1, 1))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "        \n",
    "    model = Model(model_input, x, name='all_cnn')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin_cnn(model_input):\n",
    "    \n",
    "    #mlpconv block 1\n",
    "    x = Conv2D(32, (5, 5), activation='relu',padding='valid')(model_input)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    #mlpconv block2\n",
    "    x = Conv2D(64, (3, 3), activation='relu',padding='valid')(x)\n",
    "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    #mlpconv block3\n",
    "    x = Conv2D(128, (3, 3), activation='relu',padding='valid')(x)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(7, (1, 1))(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='nin_cnn')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(models, model_input):\n",
    "    \n",
    "    outputs = [model.outputs[0] for model in models]\n",
    "    y = Average()(outputs)\n",
    "    \n",
    "    model = Model(model_input, y, name='ensemble')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import keras.callbacks as callbacks\n",
    "BATCHSIZE = 40\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "def compile_and_train(model, num_epochs, train_x, train_labels, val_x, val_labels):\n",
    "    \n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr=0.0001), metrics=[\"accuracy\"])\n",
    "    filepath = 'weights/' + model.name + '.{epoch:02d}-{loss:.2f}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, \n",
    "                                 save_weights_only=True, save_best_only=True, \n",
    "                                 mode='auto', period=1)\n",
    "#     tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=32)\n",
    "#     history = model.fit(x=x_train, y=y_train, batch_size=32, epochs=num_epochs, \n",
    "#                         verbose=1, callbacks=[checkpoint, tensor_board], \n",
    "#                         validation_split=0.2)\n",
    "    \n",
    "\n",
    "    train_categorical_labels = to_categorical(train_labels, num_classes=None)\n",
    "    val_categorical_labels = to_categorical(val_labels, num_classes=None)\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rescale=1./10,\n",
    "        fill_mode='nearest',\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False)\n",
    "\n",
    "    datagen.fit(train_x)\n",
    "\n",
    "    #Compile model\n",
    "    # ...\n",
    "\n",
    "\n",
    "\n",
    "    tbCallBacks = [callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=7,\n",
    "                                          verbose=0, mode='auto', baseline=None, \n",
    "                                          restore_best_weights=False),\n",
    "                  TensorBoard(log_dir=\"./monitor\".format(time()), write_graph=True,\n",
    "                              histogram_freq=0, batch_size=BATCHSIZE),\n",
    "                  checkpoint]\n",
    "\n",
    "    #Train model\n",
    "    # ...\n",
    "\n",
    "    history = model.fit_generator(datagen.flow(train_x, train_categorical_labels, batch_size=BATCHSIZE),\n",
    "                        validation_data=datagen.flow(val_x, val_categorical_labels, batch_size=BATCHSIZE),\n",
    "                        validation_steps=len(val_x)/BATCHSIZE,\n",
    "                        steps_per_epoch=len(train_x)/BATCHSIZE, \n",
    "                        epochs=num_epochs, use_multiprocessing=True,\n",
    "                        initial_epoch=0,\n",
    "                        callbacks=tbCallBacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_np = np.empty((35887, 48, 48, 3))\n",
    "count = 0\n",
    "with open('test_data/images.dat', 'r') as csvfile:\n",
    "    image_csv = csv.reader(csvfile, delimiter=' ')\n",
    "    for row in image_csv:\n",
    "        image_np[count] = np.stack((np.reshape(row, (48, 48)),)*3, axis=-1)\n",
    "        count += 1\n",
    "with open('test_data/labels.txt', 'r') as labels_file:\n",
    "    labels = np.asarray(labels_file.readlines()).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_data, x_label) = image_np, labels\n",
    "\n",
    "# Prepare the data\n",
    "# ...\n",
    "trainVal_x, test_x, trainVal_labels, test_labels = train_test_split(x_data, x_label, test_size=0.2, random_state=0)\n",
    "train_x, val_x, train_labels, val_labels = train_test_split(trainVal_x, trainVal_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Train/Val data. X: \", trainVal_x.shape, \", Y: \", trainVal_x.shape)\n",
    "print(\"Test data. X: \", test_x.shape, \", Y: \", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "train_categorical_labels = to_categorical(train_labels, num_classes=None)\n",
    "val_categorical_labels = to_categorical(val_labels, num_classes=None)\n",
    "test_categorical_labels = to_categorical(test_labels, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "model = ResNet50(weights='imagenet', include_top=False, input_shape=(48, 48, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.output\n",
    "x = Convolution2D(7, (1, 1), padding='valid', name='conv7')(x)\n",
    "x = Activation('relu', name='relu_7')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax', name='loss')(x)\n",
    "# x = sequential_with_svm.SequentialWithSvm()(x)\n",
    "\n",
    "model = Model(model.inputs, x, name='resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResNet = compile_and_train(model, 100, train_x, train_labels, val_x, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezeModel = SqueezeNet((48, 48, 3))\n",
    "squeezeModel = newSqueezeNet(squeezeModel)\n",
    "#new Model\n",
    "\n",
    "modelSqueeze = compile_and_train(model, 100, train_x, train_labels, val_x, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "#Add new classification layers\n",
    "x = model.output\n",
    "x = Convolution2D(7, (1, 1), padding='valid', name='conv7')(x)\n",
    "x = Activation('relu', name='relu_7')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax', name='loss')(x)\n",
    "# x = sequential_with_svm.SequentialWithSvm()(x)\n",
    "\n",
    "model = Model(model.inputs, x, name='VGG19')\n",
    "\n",
    "modelVGG19 = compile_and_train(model, 100, train_x, train_labels, val_x, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_x[0,:,:,:].shape\n",
    "model_input = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[0,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_pool_cnn_model = conv_pool_cnn(model_input)\n",
    "model_pool_cnn = compile_and_train(conv_pool_cnn_model, 100, train_x, train_labels, val_x, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeezeModel = SqueezeNet((48,48,3))\n",
    "squeezeModel = SqueezeNet(model_input)\n",
    "squeezeModel = newSqueezeNet(squeezeModel)\n",
    "squeezeModel.load_weights('./weights/squeezenet.29-0.91.hdf5')\n",
    "\n",
    "modelResNet = ResNet50(weights='imagenet', include_top=False, input_tensor=model_input)\n",
    "\n",
    "x = modelResNet.output\n",
    "x = Convolution2D(7, (1, 1), padding='valid', name='conv7')(x)\n",
    "x = Activation('relu', name='relu_7')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax', name='loss')(x)\n",
    "# x = sequential_with_svm.SequentialWithSvm()(x)\n",
    "\n",
    "modelResNet = Model(modelResNet.inputs, x, name='resnet50')\n",
    "modelResNet.load_weights('./weights/resnet50.19-0.44.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_pool_cnn_model = conv_pool_cnn(model_input)\n",
    "conv_pool_cnn_model.load_weights('./weights/conv_pool_cnn.18-0.56.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [squeezeModel, modelResNet, conv_pool_cnn_model]\n",
    "ensemble_model = ensemble(models, model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = ensemble_model.predict(test_x, batch_size=40)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "predict = np.expand_dims(predict, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newSqueezeNet(model_input):\n",
    "    #Add new classification layers\n",
    "    x = model_input.layers[-5].output\n",
    "    x = Convolution2D(7, (1, 1), padding='valid', name='new_conv10')(x)\n",
    "    x = Activation('relu', name='new_relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='new_loss')(x)\n",
    "    model = Model(squeezeModel.inputs, x, name='squeezenet')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_error(model, x, labels):\n",
    "    pred = model.predict(x, batch_size = 40)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    pred = np.expand_dims(pred, axis=1) # make same shape as y_test\n",
    "    error = np.sum(np.not_equal(pred, labels.reshape((x.shape[0], 1)))) / test_labels.shape[0]\n",
    "  \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_error(ensemble_model, val_x, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressions = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "count = 0\n",
    "for i in predict[:100]:\n",
    "    plt.imshow(test_x[count,:,:,0], cmap='gray')\n",
    "    plt.show()\n",
    "    print('predicted: {}, correct: {}'.format(expressions[i[-1]], expressions[test_labels[count]]))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
